{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct file path for PeterMac data\n",
    "data_file_path = Path('../Resources/PeterMac_HRD_Validation.csv')\n",
    "data_df = pd.read_csv(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Source</th>\n",
       "      <th>Purity</th>\n",
       "      <th>MIDS</th>\n",
       "      <th>TotalReads(M)</th>\n",
       "      <th>lpWGSReads(M)</th>\n",
       "      <th>TargetPanelReads(M)</th>\n",
       "      <th>%ReadslpWGS</th>\n",
       "      <th>%ReadsPanel</th>\n",
       "      <th>1000x</th>\n",
       "      <th>...</th>\n",
       "      <th>ResNoise</th>\n",
       "      <th>SignalNoiseRatio</th>\n",
       "      <th>QAStatus</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variant</th>\n",
       "      <th>%VariantFraction</th>\n",
       "      <th>MyriadGIScore</th>\n",
       "      <th>MyriadGIStatus</th>\n",
       "      <th>SOPHiAGIIndex</th>\n",
       "      <th>SophiaGIStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>81%</td>\n",
       "      <td>19%</td>\n",
       "      <td>1%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.95</td>\n",
       "      <td>Medium</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>76%</td>\n",
       "      <td>24%</td>\n",
       "      <td>2%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.91</td>\n",
       "      <td>High</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>-15.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>64%</td>\n",
       "      <td>36%</td>\n",
       "      <td>41%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.64</td>\n",
       "      <td>High</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>63%</td>\n",
       "      <td>37%</td>\n",
       "      <td>16%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.49</td>\n",
       "      <td>High</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>58%</td>\n",
       "      <td>42%</td>\n",
       "      <td>2%</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.18</td>\n",
       "      <td>High</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run Source Purity  MIDS  TotalReads(M)  lpWGSReads(M)  TargetPanelReads(M)  \\\n",
       "0    1     AZ     20     2            7.3            5.9                  1.4   \n",
       "1    1     AZ     30     3            7.3            5.6                  1.7   \n",
       "2    1     AZ     20     4            9.6            6.1                  3.5   \n",
       "3    1     AZ     20     6            8.9            5.6                  3.3   \n",
       "4    1     AZ     60     7            8.6            5.0                  3.6   \n",
       "\n",
       "  %ReadslpWGS %ReadsPanel 1000x  ... ResNoise SignalNoiseRatio QAStatus Gene  \\\n",
       "0         81%         19%    1%  ...     0.13             2.95   Medium    .   \n",
       "1         76%         24%    2%  ...     0.11             2.91     High    .   \n",
       "2         64%         36%   41%  ...      0.1             1.64     High    .   \n",
       "3         63%         37%   16%  ...     0.09             3.49     High    .   \n",
       "4         58%         42%    2%  ...     0.11             2.18     High    .   \n",
       "\n",
       "  Variant %VariantFraction  MyriadGIScore MyriadGIStatus SOPHiAGIIndex  \\\n",
       "0       .                .             51              1           3.2   \n",
       "1       .                .             20              2         -15.7   \n",
       "2       .                .             17              2          -4.6   \n",
       "3       .                .             29              2          -4.6   \n",
       "4       .                .             29              2          -8.2   \n",
       "\n",
       "  SophiaGIStatus  \n",
       "0              1  \n",
       "1              2  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  YOUR CODE GOES HERE\n",
    "columns_to_drop = [\"SampleID\", \"SeqRunID\", \"DDMSampleID\",\"MonthsOld\"]\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "data_df = data_df.drop(columns=columns_to_drop, axis=1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity    object\n",
      "dtype: object\n",
      "Purity    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert columns we will not bin, from pobject type to numeric\n",
    "column_names_to_convert = ['Purity']\n",
    "\n",
    "# Step 1: Check the current data types of the columns\n",
    "print(data_df[column_names_to_convert].dtypes)\n",
    "\n",
    "# Step 2: Convert each column to numeric (if possible)\n",
    "for col in column_names_to_convert:\n",
    "    data_df[col] = pd.to_numeric(data_df[col], errors='coerce')\n",
    "\n",
    "# Step 3: Check the new data types of the columns after the conversion\n",
    "print(data_df[column_names_to_convert].dtypes)\n",
    "# print(data_df[\"Source\"].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['PurityPloidyRatio'] = data_df['PurityPloidyRatio'].replace('-', 0.0)\n",
    "data_df['ResNoise'] = data_df['ResNoise'].replace('-', 0.0)\n",
    "data_df['SignalNoiseRatio'] = data_df['SignalNoiseRatio'].replace('-', 0.0)\n",
    "\n",
    "data_df['Gene'] = data_df['Gene'].replace('.', 'Unlisted')\n",
    "\n",
    "\n",
    "# data_df['MonthsOld'] = data_df['MonthsOld'].fillna(0.0)\n",
    "# data_df['MonthsOld'] = data_df['MonthsOld'].replace('.', 0.0)\n",
    "data_df['Purity'] = data_df['Purity'].replace('.', 0.0)\n",
    "data_df['%VariantFraction'] = data_df['%VariantFraction'].replace('.', 0.0)\n",
    "\n",
    "# Convert the 'Purity' column to numeric, replacing '.' with 0.0\n",
    "data_df['Purity'] = pd.to_numeric(data_df['Purity'], errors='coerce').fillna(0.0)\n",
    "\n",
    "data_df['DupFrac'] = data_df['DupFrac'].replace('%', '', regex=True).astype(float)\n",
    "data_df['%ReadslpWGS'] = data_df['%ReadslpWGS'].replace('%', '', regex=True).astype(float)\n",
    "data_df['%ReadsPanel'] = data_df['%ReadsPanel'].replace('%', '', regex=True).astype(float)\n",
    "\n",
    "data_df['Variant'] = data_df['Variant'].replace('.', 'Unlisted')\n",
    "\n",
    "# Apply label encoding to 'Variant' column\n",
    "label_encoder = LabelEncoder()\n",
    "data_df['Variant'] = label_encoder.fit_transform(data_df['Variant'].astype(str))\n",
    "\n",
    "data_df['1000x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)\n",
    "\n",
    "data_df['500x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)\n",
    "data_df['200x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)\n",
    "data_df['100x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)\n",
    "data_df['50x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)\n",
    "data_df['25x'] = data_df['1000x'].replace('%', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_non_agreement(row):\n",
    "    if row['MyriadGIStatus'] == 1 and row['SophiaGIStatus'] == 1:\n",
    "        return 1\n",
    "    elif row['MyriadGIStatus'] == 1 and row['SophiaGIStatus'] == 2:\n",
    "        return 0\n",
    "    elif row['MyriadGIStatus'] == 1 and row['SophiaGIStatus'] == 3:\n",
    "        return 0\n",
    "    elif row['MyriadGIStatus'] == 1 and row['SophiaGIStatus'] == 4:\n",
    "        return 0\n",
    "    elif row['MyriadGIStatus'] == 2 and row['SophiaGIStatus'] == 1:\n",
    "        return 0\n",
    "    elif row['MyriadGIStatus'] == 2 and row['SophiaGIStatus'] == 2:\n",
    "        return 1\n",
    "    elif row['MyriadGIStatus'] == 2 and row['SophiaGIStatus'] == 3:\n",
    "        return 0\n",
    "    elif row['MyriadGIStatus'] == 2 and row['SophiaGIStatus'] == 4:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the 'Non-agreement' column\n",
    "data_df['Non-agreement'] = data_df.apply(calculate_non_agreement, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot columns for these 3 columns\n",
    "onehot_cols = [\"QAStatus\", \"Gene\", \"Variant\"]  #\"PurityPloidyRatio\"]\n",
    "\n",
    "# Use get_dummies() to one-hot encode only the categorical columns\n",
    "one_hot_encoded = pd.get_dummies(data_df[onehot_cols])\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "data_df = pd.concat([data_df, one_hot_encoded], axis=1)\n",
    "\n",
    "# After this, you can print the data types of columns in the 'data_df' DataFrame\n",
    "column_types = data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Run', 'Source', 'Purity', 'MIDS', 'TotalReads(M)', 'lpWGSReads(M)',\n",
       "       'TargetPanelReads(M)', '%ReadslpWGS', '%ReadsPanel', '1000x', '500x',\n",
       "       '200x', '100x', '50x', '25x', 'DupFrac', 'LowCovRegions',\n",
       "       'PurityPloidyRatio', 'ResNoise', 'SignalNoiseRatio', 'Variant',\n",
       "       '%VariantFraction', 'Variant', 'QAStatus_High', 'QAStatus_Low',\n",
       "       'QAStatus_Medium', 'Gene_BRCA1', 'Gene_BRCA2', 'Gene_RAD51D',\n",
       "       'Gene_Unlisted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1  pca method on application_df which has had bucketing performed for the original model.\n",
    "data_df_x = data_df.copy() \n",
    "columns_to_drop = [\"Gene\", \"Non-agreement\", \"MyriadGIStatus\", \"SophiaGIStatus\", \"MyriadGIScore\", \"SOPHiAGIIndex\", \"QAStatus\"]\n",
    "data_df_x = data_df_x.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "#data_df_x = data_df_x.drop(columns=[\"Gene\",\"Source\",\"Non_agreement\", \"MyriadGIStatus\", \"SophiaGIStatus\", \"MyriadGIScore\", \"SOPHiAGIIndex\",\"QAStatus\"], axis=1)\n",
    "data_df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"Deleted\" with 0 in the '%ReadslpWGS' column\n",
    "data_df_x['%VariantFraction'] = data_df_x['%VariantFraction'].replace('Deleted', 0)\n",
    "\n",
    "# Convert the column to numeric (float) format\n",
    "data_df_x['%VariantFraction'] = pd.to_numeric(data_df_x['%VariantFraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run                      int64\n",
      "Source                  object\n",
      "Purity                 float64\n",
      "MIDS                     int64\n",
      "TotalReads(M)          float64\n",
      "lpWGSReads(M)          float64\n",
      "TargetPanelReads(M)    float64\n",
      "%ReadslpWGS            float64\n",
      "%ReadsPanel            float64\n",
      "1000x                  float64\n",
      "500x                   float64\n",
      "200x                   float64\n",
      "100x                   float64\n",
      "50x                    float64\n",
      "25x                    float64\n",
      "DupFrac                float64\n",
      "LowCovRegions            int64\n",
      "PurityPloidyRatio       object\n",
      "ResNoise                object\n",
      "SignalNoiseRatio        object\n",
      "Variant                  int64\n",
      "%VariantFraction       float64\n",
      "Variant                  int64\n",
      "QAStatus_High            uint8\n",
      "QAStatus_Low             uint8\n",
      "QAStatus_Medium          uint8\n",
      "Gene_BRCA1               uint8\n",
      "Gene_BRCA2               uint8\n",
      "Gene_RAD51D              uint8\n",
      "Gene_Unlisted            uint8\n",
      "dtype: object\n",
      "Run                    0\n",
      "Source                 0\n",
      "Purity                 0\n",
      "MIDS                   0\n",
      "TotalReads(M)          0\n",
      "lpWGSReads(M)          0\n",
      "TargetPanelReads(M)    0\n",
      "%ReadslpWGS            0\n",
      "%ReadsPanel            0\n",
      "1000x                  0\n",
      "500x                   0\n",
      "200x                   0\n",
      "100x                   0\n",
      "50x                    0\n",
      "25x                    0\n",
      "DupFrac                0\n",
      "LowCovRegions          0\n",
      "PurityPloidyRatio      0\n",
      "ResNoise               0\n",
      "SignalNoiseRatio       0\n",
      "Variant                0\n",
      "%VariantFraction       0\n",
      "Variant                0\n",
      "QAStatus_High          0\n",
      "QAStatus_Low           0\n",
      "QAStatus_Medium        0\n",
      "Gene_BRCA1             0\n",
      "Gene_BRCA2             0\n",
      "Gene_RAD51D            0\n",
      "Gene_Unlisted          0\n",
      "dtype: int64\n",
      "Run                      0\n",
      "Source                 139\n",
      "Purity                   0\n",
      "MIDS                     0\n",
      "TotalReads(M)            0\n",
      "lpWGSReads(M)            0\n",
      "TargetPanelReads(M)      0\n",
      "%ReadslpWGS              0\n",
      "%ReadsPanel              0\n",
      "1000x                    0\n",
      "500x                     0\n",
      "200x                     0\n",
      "100x                     0\n",
      "50x                      0\n",
      "25x                      0\n",
      "DupFrac                  0\n",
      "LowCovRegions            0\n",
      "PurityPloidyRatio        0\n",
      "ResNoise                 0\n",
      "SignalNoiseRatio         0\n",
      "Variant                  0\n",
      "%VariantFraction         0\n",
      "Variant                  0\n",
      "QAStatus_High            0\n",
      "QAStatus_Low             0\n",
      "QAStatus_Medium          0\n",
      "Gene_BRCA1               0\n",
      "Gene_BRCA2               0\n",
      "Gene_RAD51D              0\n",
      "Gene_Unlisted            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types of the columns in data_df_x\n",
    "print(data_df_x.dtypes)\n",
    "\n",
    "# Check for missing values in data_df_x\n",
    "print(data_df_x.isnull().sum())\n",
    "\n",
    "# Convert the '%VariantFraction' column to numeric values, invalid values will be converted to NaN\n",
    "data_df_x['%VariantFraction'] = pd.to_numeric(data_df_x['%VariantFraction'], errors='coerce')\n",
    "\n",
    "# Create a mask to identify rows with NaN values in the '%VariantFraction' column\n",
    "invalid_rows_mask = data_df_x['%VariantFraction'].isna()\n",
    "\n",
    "# Use the mask to filter the DataFrame and get the rows with invalid values\n",
    "invalid_rows = data_df_x[invalid_rows_mask]\n",
    "\n",
    "# Check if any non-numeric values still exist in data_df_x\n",
    "non_numeric_values = data_df_x.apply(pd.to_numeric, errors='coerce').isnull().sum()\n",
    "print(non_numeric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Run', 'Purity', 'MIDS', 'TotalReads(M)', 'lpWGSReads(M)',\n",
       "       'TargetPanelReads(M)', '%ReadslpWGS', '%ReadsPanel', '1000x', '500x',\n",
       "       '200x', '100x', '50x', '25x', 'DupFrac', 'LowCovRegions',\n",
       "       'PurityPloidyRatio', 'ResNoise', 'SignalNoiseRatio', '%VariantFraction',\n",
       "       'QAStatus_High', 'QAStatus_Low', 'QAStatus_Medium', 'Gene_BRCA1',\n",
       "       'Gene_BRCA2', 'Gene_RAD51D', 'Gene_Unlisted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['Variant', 'Source']\n",
    "data_df_x = data_df_x.drop(columns=columns_to_drop)\n",
    "\n",
    "data_df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Run, Purity, MIDS, TotalReads(M), lpWGSReads(M), TargetPanelReads(M), %ReadslpWGS, %ReadsPanel, 1000x, 500x, 200x, 100x, 50x, 25x, DupFrac, LowCovRegions, PurityPloidyRatio, ResNoise, SignalNoiseRatio, %VariantFraction, QAStatus_High, QAStatus_Low, QAStatus_Medium, Gene_BRCA1, Gene_BRCA2, Gene_RAD51D, Gene_Unlisted]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "invalid_rows = data_df_x['%VariantFraction'].apply(lambda x: not str(x).replace('.', '').isnumeric())\n",
    "\n",
    "# Display the rows containing the invalid values\n",
    "print(data_df_x[invalid_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 27)\n",
      "(111, 27) (28, 27)\n",
      "(111, 3) (28, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y2 = data_df[\"Non-agreement\"].values\n",
    "X2 = data_df_x.values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=78)\n",
    "\n",
    "# Now perform PCA only on the training data\n",
    "pca = PCA(n_components=3)\n",
    "X2_train_pca = pca.fit_transform(X2_train)\n",
    "\n",
    "# Apply the same PCA transformation to the testing data\n",
    "X2_test_pca = pca.transform(X2_test)\n",
    "\n",
    "# Check the number of records in the original dataset\n",
    "print(data_df_x.shape)\n",
    "\n",
    "# Check the number of records after splitting into training and testing sets\n",
    "print(X2_train.shape, X2_test.shape)\n",
    "\n",
    "# Check the number of records after PCA transformation\n",
    "print(X2_train_pca.shape, X2_test_pca.shape)\n",
    "\n",
    "# Create a new DataFrame with the PCA data for both training and testing sets\n",
    "df_train_pca = pd.DataFrame(X2_train_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "df_test_pca = pd.DataFrame(X2_test_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X2_scaler = scaler.fit(X2_train)\n",
    "\n",
    "# Scale the data\n",
    "X2_train_scaled = X2_scaler.transform(X2_train)\n",
    "X2_test_scaled = X2_scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=2), activation=activation, input_dim=27))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=100,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 500 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.7142857313156128\n",
      "\n",
      "Best val_accuracy So Far: 0.8571428656578064\n",
      "Total elapsed time: 00h 19m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X2_train_scaled,y2_train,epochs=100,validation_data=(X2_test_scaled,y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 11,\n",
       " 'num_layers': 3,\n",
       " 'units_0': 13,\n",
       " 'units_1': 13,\n",
       " 'units_2': 13,\n",
       " 'units_3': 11,\n",
       " 'units_4': 29,\n",
       " 'units_5': 25,\n",
       " 'tuner/epochs': 12,\n",
       " 'tuner/initial_epoch': 4,\n",
       " 'tuner/bracket': 3,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0151'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.5823 - accuracy: 0.8571 - 245ms/epoch - 245ms/step\n",
      "Loss: 0.58232581615448, Accuracy: 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X2_test_scaled,y2_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
