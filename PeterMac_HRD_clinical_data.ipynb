{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the source folder\n",
    "source_folder = './Resources/PeterMac_HRD_Clinical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames of files with 'sample' column\n",
    "qa_gi_file = glob.glob(source_folder + '*-combined_QA_GI_status.csv')\n",
    "lc_table_file = glob.glob(source_folder + '*-combined_LC_table.csv')\n",
    "cov_decay_file = glob.glob(source_folder + 'concat_cov_decay.csv')\n",
    "dup_frac_file = glob.glob(source_folder + 'concat_dup_frac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filename of files with 'episode'\n",
    "mids_ep_file = glob.glob(source_folder + '*-combined_MIDS_episode.csv')\n",
    "ee_dump_file = glob.glob(source_folder + 'HRD_Report_clean_EE_dump_*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files into DataFrames\n",
    "qa_gi_df = pd.read_csv(qa_gi_file[0])\n",
    "lc_table_df = pd.read_csv(lc_table_file[0])\n",
    "cov_decay_df = pd.read_csv(cov_decay_file[0])\n",
    "dup_frac_df = pd.read_csv(dup_frac_file[0])\n",
    "mids_ep_df = pd.read_csv(mids_ep_file[0])\n",
    "ee_dump_df = pd.read_csv(ee_dump_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on 'Sample' column\n",
    "sample_merged_df = pd.merge(qa_gi_df, lc_table_df, on='Sample')\n",
    "sample_merged_df = pd.merge(sample_merged_df, cov_decay_df, on='Sample')\n",
    "sample_merged_df = pd.merge(sample_merged_df, dup_frac_df, on='Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate, tidy, drop columns\n",
    "sample_merged_df['MIDS'] = sample_merged_df['Sample'].str.split('-').str[-1]\n",
    "sample_merged_df['Panel(M)'] = sample_merged_df['Total(M)']-sample_merged_df['WGS(M)']\n",
    "sample_merged_df['Run'] = sample_merged_df['Run'].str.split('_').str[-1]\n",
    "sample_merged_df.drop(columns=['QA_status','%CovOut', 'Cov_10%_qtile', 'Cov Het'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix % columns\n",
    "percent_columns = ['%WGS', '25x', '50x', '100x', '200x', '500x', '1000x', 'Duplicate Fraction']\n",
    "for column in percent_columns:\n",
    "    sample_merged_df[column] = pd.to_numeric(sample_merged_df[column].str.replace('%',''), errors='coerce') / 100\n",
    "    sample_merged_df[column] = sample_merged_df[column].apply(lambda x: round(x, 2))\n",
    "sample_merged_df['%Panel'] = 1 - sample_merged_df['%WGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix numeric columns\n",
    "numeric_columns = ['GI_index', 'PPR']\n",
    "for column in numeric_columns:\n",
    "    sample_merged_df[column] = pd.to_numeric(sample_merged_df[column].replace('-', np.nan), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to hyphenate episode number\n",
    "def hyphenate(episode):\n",
    "    ep_str = str(episode)\n",
    "    hyphen_ep = ep_str[:-4] + '-' + ep_str[-4:]\n",
    "    return hyphen_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyphenate mids_ep_df 'Episode'\n",
    "mids_ep_df['Episode'] = mids_ep_df['Episode'].apply(hyphenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on 'Episode' column\n",
    "episode_merged_df = pd.merge(mids_ep_df, ee_dump_df, on='Episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get header list for episode_merged_df \n",
    "header_list = episode_merged_df.columns.tolist()\n",
    "\n",
    "# Write header list to text file for editing\n",
    "with open('episode_merged_headers.txt', 'w') as f:\n",
    "    for item in header_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use edited header list to delete extraneous columns\n",
    "with open('episode_keep_headers.txt', 'r') as f:\n",
    "    keep_episode_merged_headers = [line.strip() for line in f.readlines()]\n",
    "episode_merged_df = episode_merged_df[keep_episode_merged_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate, tidy columns\n",
    "episode_merged_df['Run'] = episode_merged_df['Run'].str.split('_').str[-1]\n",
    "episode_merged_df['VAF_1'] = pd.to_numeric(episode_merged_df['VAF_1'].replace('-', np.nan), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge episode-merged and sample-merged dataframes on 'Run' and 'MIDS'\n",
    "full_merged_df = pd.merge(sample_merged_df, episode_merged_df, on=['Run', 'MIDS'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>GI_index</th>\n",
       "      <th>GI_status</th>\n",
       "      <th>Total(M)</th>\n",
       "      <th>WGS(M)</th>\n",
       "      <th>%WGS</th>\n",
       "      <th>PPR</th>\n",
       "      <th>RN</th>\n",
       "      <th>SNR</th>\n",
       "      <th>QAStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>Panel(M)</th>\n",
       "      <th>%Panel</th>\n",
       "      <th>Episode</th>\n",
       "      <th>State/Territory</th>\n",
       "      <th>Collected</th>\n",
       "      <th>Received</th>\n",
       "      <th>Est Tum Purity</th>\n",
       "      <th>Gene_1</th>\n",
       "      <th>HGVSp_1</th>\n",
       "      <th>VAF_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200085906-407-S10</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.08</td>\n",
       "      <td>Medium</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1410-1517</td>\n",
       "      <td>TAS</td>\n",
       "      <td>23/5/2023</td>\n",
       "      <td>31/5/2023</td>\n",
       "      <td>90.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>p.(Thr155Serfs*6)</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200085907-387-S11</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>21.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.34</td>\n",
       "      <td>Medium</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1413-3340</td>\n",
       "      <td>QLD</td>\n",
       "      <td>1/6/2023</td>\n",
       "      <td>9/6/2023</td>\n",
       "      <td>25.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>p.(Ile195Thr)</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200085909-404-S13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.64</td>\n",
       "      <td>High</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1410-3300</td>\n",
       "      <td>TAS</td>\n",
       "      <td>15/5/2023</td>\n",
       "      <td>1/6/2023</td>\n",
       "      <td>90.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>p.(Arg158Hisfs*21)</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200085910-394-S14</td>\n",
       "      <td>10.2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.67</td>\n",
       "      <td>High</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1413-4688</td>\n",
       "      <td>VIC</td>\n",
       "      <td>7/6/2023</td>\n",
       "      <td>20/6/2023</td>\n",
       "      <td>70.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>p.(Cys238Phe)</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200085911-388-S15</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.64</td>\n",
       "      <td>High</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1407-7410</td>\n",
       "      <td>VIC</td>\n",
       "      <td>26/5/2023</td>\n",
       "      <td>26/5/2023</td>\n",
       "      <td>80.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>p.(?)</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sample  GI_index GI_status  Total(M)  WGS(M)  %WGS   PPR    RN  \\\n",
       "0  200085906-407-S10       8.8  Positive      22.1    14.2  0.64   NaN  0.08   \n",
       "1  200085907-387-S11       9.2  Positive      21.8    18.7  0.86   NaN  0.08   \n",
       "2  200085909-404-S13       0.8  Positive      22.5    16.5  0.73  0.28  0.07   \n",
       "3  200085910-394-S14      10.2  Positive      21.0    16.9  0.80  0.20  0.08   \n",
       "4  200085911-388-S15       4.7  Positive      17.0    13.1  0.77  0.45  0.10   \n",
       "\n",
       "    SNR QAStatus  ... Panel(M)  %Panel    Episode  State/Territory  Collected  \\\n",
       "0  4.08   Medium  ...      7.9    0.36  1410-1517              TAS  23/5/2023   \n",
       "1  1.34   Medium  ...      3.1    0.14  1413-3340              QLD   1/6/2023   \n",
       "2  4.64     High  ...      6.0    0.27  1410-3300              TAS  15/5/2023   \n",
       "3  4.67     High  ...      4.1    0.20  1413-4688              VIC   7/6/2023   \n",
       "4  3.64     High  ...      3.9    0.23  1407-7410              VIC  26/5/2023   \n",
       "\n",
       "    Received  Est Tum Purity  Gene_1             HGVSp_1 VAF_1  \n",
       "0  31/5/2023            90.0    TP53   p.(Thr155Serfs*6)  92.0  \n",
       "1   9/6/2023            25.0    TP53       p.(Ile195Thr)  16.0  \n",
       "2   1/6/2023            90.0    TP53  p.(Arg158Hisfs*21)  79.0  \n",
       "3  20/6/2023            70.0    TP53       p.(Cys238Phe)  61.0  \n",
       "4  26/5/2023            80.0    TP53               p.(?)  77.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-BRCA entries\n",
    "condition = ~((full_merged_df['Gene_1'] == 'BRCA1') | (full_merged_df['Gene_1'] == 'BRCA2'))\n",
    "full_merged_df['GI_status'] = full_merged_df['GI_status'].replace('Negative*', 'Negative')\n",
    "modify_columns = ['Gene_1', 'HGVSp_1', 'VAF_1']\n",
    "modify_rows = full_merged_df.index[condition]\n",
    "full_merged_df.loc[modify_rows, modify_columns] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DropNA rows for Date and Purity\n",
    "drop_columns = ['Collected', 'Received', 'Est Tum Purity']\n",
    "full_merged_df.dropna(subset=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/33/871465hj6hg_b84yp3h29nt8cd0w4h/T/ipykernel_96404/1655650781.py:2: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  full_merged_df['Collected'] = pd.to_datetime(full_merged_df['Collected'])\n",
      "/var/folders/33/871465hj6hg_b84yp3h29nt8cd0w4h/T/ipykernel_96404/1655650781.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  full_merged_df['Received'] = pd.to_datetime(full_merged_df['Received'])\n"
     ]
    }
   ],
   "source": [
    "# Calculate sample age\n",
    "full_merged_df['Collected'] = pd.to_datetime(full_merged_df['Collected'])\n",
    "full_merged_df['Received'] = pd.to_datetime(full_merged_df['Received'])\n",
    "full_merged_df['DaysOld'] = (full_merged_df['Received'] - full_merged_df['Collected']).dt.days\n",
    "full_merged_df.drop(columns=['Collected','Received'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get header list for full_merged_df \n",
    "header_list = full_merged_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write header list to text file for manual re-ordering\n",
    "with open('full_merged_headers_unordered.txt', 'w') as f:\n",
    "    for item in header_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read re-ordered old headers to list\n",
    "with open('full_merged_headers_reordered.txt', 'r') as f:\n",
    "    old_headers = [line.strip() for line in f.readlines()]\n",
    "    # print(len(old_headers))\n",
    "\n",
    "# Read new header names to list (matching columns in 'PeterMac_HRD_Validation.csv')\n",
    "with open('new_clin_column_names.txt', 'r') as f:\n",
    "    new_headers = [line.strip() for line in f.readlines()]\n",
    "    # print(len(new_headers))\n",
    "\n",
    "# Create column re-naming dictionary\n",
    "rename_dict = dict(zip(old_headers, new_headers))\n",
    "# rename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and reorder columns\n",
    "full_merged_df = full_merged_df.reindex(columns=rename_dict).rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged DataFrame to CSV file\n",
    "full_merged_df.to_csv(source_folder + 'PeterMac_HRD_clinical_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
